{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case of problems or questions, please first check the list of [Frequently Asked Questions (FAQ)](https://stardist.net/docs/faq.html).**\n",
    "\n",
    "Please shutdown all other training/prediction notebooks before running this notebook (as those might occupy the GPU memory otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from stardist import random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist import Rays_GoldenSpiral\n",
    "from stardist.matching import matching_dataset\n",
    "from stardist.models import Config3D, StarDist3D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "from os import listdir, makedirs\n",
    "from pathlib import Path\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenCL-based computations for data generator during training (requires 'gputools')\n",
    "use_gpu = True and gputools_available()\n",
    "\n",
    "print('/!\\ USING GPU: ', use_gpu)\n",
    "\n",
    "# If you need to limit the GPU memory used by TensorFlow/StarDist, you can specify that here \n",
    "# from csbdeep.utils.tf import limit_gpu_memory\n",
    "# # adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "# limit_gpu_memory(0.8, total_memory=48682)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Training data (for input `X` with associated label masks `Y`) can be provided via lists of numpy arrays, where each image can have a different size. Alternatively, a single numpy array can also be used if all images have the same size.  \n",
    "Input images can either be three-dimensional (single-channel) or four-dimensional (multi-channel) arrays, where the channel axis comes last. Label images need to be integer-valued.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel = 1\n",
    "path_to_data = folder = Path(globals()['_dh'][0]).parents[1] / 'data'\n",
    "path_to_trainval_data = path_to_data / 'datasets_for_stardist/trainval_dataset'\n",
    " \n",
    "\n",
    "X_trn = [tifffile.imread(path_to_trainval_data / f'train/imgs/{file}') for file in listdir(path_to_trainval_data / f'train/imgs')]\n",
    "Y_trn = [tifffile.imread(path_to_trainval_data / f'train/masks/{file}') for file in listdir(path_to_trainval_data / f'train/masks')]\n",
    "\n",
    "X_val = [tifffile.imread(path_to_trainval_data / f'val/imgs/{file}') for file in listdir(path_to_trainval_data / f'val/imgs')]\n",
    "Y_val = [tifffile.imread(path_to_trainval_data / f'val/masks/{file}') for file in listdir(path_to_trainval_data / f'val/masks')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image (XY slice)\", lbl_title=\"label (XY slice)\", z=None, **kwargs):\n",
    "    if z is None:\n",
    "        z = img.shape[0] // 2    \n",
    "    fig, (ai,al) = plt.subplots(1,2, figsize=(12,5), gridspec_kw=dict(width_ratios=(1.25,1)))\n",
    "    im = ai.imshow(img[z], cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)    \n",
    "    fig.colorbar(im, ax=ai)\n",
    "    al.imshow(lbl[z], cmap=lbl_cmap)\n",
    "    al.set_title(lbl_title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    plt.figure()\n",
    "    plt.imshow(X_trn[0][i*8], cmap='gray', clim=(0,1))\n",
    "    plt.figure()\n",
    "    plt.imshow(Y_trn[0][i*8], cmap=lbl_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "A `StarDist3D` model is specified via a `Config3D` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Config3D.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = calculate_extents(Y_trn)\n",
    "anisotropy = tuple(np.max(extents) / extents)\n",
    "print(extents)\n",
    "print('empirical anisotropy of labeled objects = %s' % str(anisotropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 96 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 64\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "#grid = tuple(1 if a > 1.5 else 2 for a in anisotropy)\n",
    "grid = (2,2,2)\n",
    "#grid = (1,1,1)\n",
    "\n",
    "# Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n",
    "rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n",
    "\n",
    "conf = Config3D (\n",
    "    rays             = rays,\n",
    "    grid             = grid,\n",
    "    anisotropy       = anisotropy,\n",
    "    use_gpu          = use_gpu,\n",
    "    n_channel_in     = n_channel,\n",
    "    # adjust for your data below (make patch size as large as possible)\n",
    "    train_patch_size = (64,64,64),\n",
    "    train_batch_size = 8,\n",
    "    train_epochs = 500,\n",
    "    train_steps_per_epoch = 20,\n",
    "    train_reduce_lr={'factor': 0.3, 'patience': 30}\n",
    ")\n",
    "#print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist3D.from_pretrained('3D_demo')\n",
    "model.config.anisotropy = (2,2,2)\n",
    "model.config.rays_json = {'name': 'Rays_GoldenSpiral',\n",
    "  'kwargs': {'n': 64, 'anisotropy': (1.0, 1.0, 1.0)}}\n",
    "\n",
    "model.config.train_learning_rate= 0.0002\n",
    "model.config.name='new_model'\n",
    "\n",
    "makedirs(path_to_data / 'stardist_models', exist_ok=True)\n",
    "\n",
    "model.basedir = path_to_data / 'stardist_models'\n",
    "model.logdir = path_to_data / 'stardist_models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The trained `StarDist3D` model will *not* predict completed shapes for partially visible objects at the image boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the neural network has a large enough field of view to see up to the boundary of most objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_size = calculate_extents(Y_trn, np.median)\n",
    "fov = np.array(model._axes_tile_overlap('ZYX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define a function/callable that applies augmentation to each batch of the data generator.  \n",
    "We here use an `augmenter` that applies random rotations, flips, and intensity changes, which are typically sensible for (3D) microscopy images (but you can disable augmentation by setting `augmenter = None`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If augmend is not installed, use \"!pip install git+https://github.com/stardist/augmend.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/stardist/augmend.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmend import Augmend, FlipRot90, Elastic, Identity, IntensityScaleShift, AdditiveNoise, Scale, Rotate\n",
    "\n",
    "\n",
    "rotation_kwargs = dict(axis=(1,2), use_gpu=True)\n",
    "\n",
    "aug = Augmend()\n",
    "# aug.add([Scale(amount=(.5,2), order=1, use_gpu=use_gpu), Scale(amount=(.5,2), order=0, use_gpu=use_gpu)], probability=0.5)\n",
    "aug.add([Rotate(order=1,axis=(1,2), use_gpu=True),Rotate(order=0,axis=(1,2), use_gpu=True)], probability=0.5)\n",
    "\n",
    "aug.add([FlipRot90(axis=(0,1,2)),FlipRot90(axis=(0,1,2))],probability=0.75)\n",
    "aug.add([IntensityScaleShift(),Identity()],probability=0.75)\n",
    "\n",
    "aug.add([AdditiveNoise(sigma=0.05), Identity()],probability=0.5)\n",
    "\n",
    "\n",
    "def augmenter(x,y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    return aug([x,y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some augmented examples\n",
    "img, lbl = X_trn[1],Y_trn[1]\n",
    "plot_img_label(img, lbl)\n",
    "\n",
    "for _ in range(10):\n",
    "    img_aug, lbl_aug = augmenter(img,lbl)\n",
    "    plot_img_label(img_aug, lbl_aug, img_title=\"image augmented (XY slice)\", lbl_title=\"label augmented (XY slice)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend to monitor the progress during training with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard). You can start it in the shell from the current working directory like this:\n",
    "\n",
    "    $ tensorboard --logdir=.\n",
    "\n",
    "Then connect to [http://localhost:6006/](http://localhost:6006/) with your browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case the training has been interrupted:\n",
    "model._training_finished()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize_thresholds(X_val, Y_val, nms_threshs=np.linspace(0.1, 0.6, 6), iou_threshs=np.linspace(0.1, 0.6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Detection Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a GT/prediction example  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_label(X_val[0],Y_val[0], lbl_title=\"label GT (XY slice)\")\n",
    "plot_img_label(X_val[0],Y_val_pred[0], lbl_title=\"label Pred (XY slice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'):\n",
    "    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax1.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax1.set_ylabel('Metric value')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "for m in ('fp', 'tp', 'fn'):\n",
    "    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax2.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax2.set_ylabel('Number #')\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
